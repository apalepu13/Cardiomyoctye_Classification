{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cardiomyocyte Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# import modules\n",
    "# ============================================================================\n",
    "# Note that this part of the code needs to be run prior to any other code cell\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import random as rnd\n",
    "\n",
    "# inline plots\n",
    "%matplotlib inline\n",
    "\n",
    "# set random number generator seed\n",
    "rnd.seed(10)\n",
    "\n",
    "# ============================================================================\n",
    "# data loading\n",
    "# ============================================================================\n",
    "matfile = 'Adult_samples.mat'\n",
    "\n",
    "# get data as dictionary (use adata.keys() to see its keys)\n",
    "adata = scipy.io.loadmat(matfile)\n",
    "\n",
    "atrial_set= adata.get('Vatrial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing & Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to normalize data\n",
    "def normalize(signal):\n",
    "    min=np.min(signal)\n",
    "    max=np.max (signal)\n",
    "    signal = (signal - min) / (max - min)\n",
    "    return signal\n",
    "\n",
    "##Create training data set by first selecting 100 random indices and then populating a matrix with the corresponding values in the data sets for each atrial and ventricular data\n",
    "atrial_nums= rnd.sample(list(range(0,1000)), 100)\n",
    "atrial_full= adata.get('Vatrial')\n",
    "\n",
    "for i in range (np.size(atrial_full,1)):\n",
    "    atrial_full [:,i]=normalize(atrial_full[:,i])\n",
    "atrial_training= atrial_full[:,atrial_nums]\n",
    "\n",
    "vent_nums=rnd.sample(list(range(0,1000)), 100)\n",
    "vent_full= adata.get('Vventricular')\n",
    "\n",
    "for i in range (np.size(vent_full,1)):\n",
    "    vent_full [:,i]=normalize(vent_full[:,i])\n",
    "    \n",
    "vent_training= vent_full[:,vent_nums]\n",
    "\n",
    "##Create testing data set by populating all the data that was not included in the training data set into a testing array (900 values per classification)\n",
    "atrial_testing=np.zeros((np.size(atrial_full, 0),900))\n",
    "vent_testing=np.zeros((np.size(atrial_full,0),900))\n",
    "a = 0\n",
    "v = 0\n",
    "for i in range (0,1000):\n",
    "    if i not in atrial_nums:\n",
    "        atrial_testing[:, a] = atrial_full[:,i]\n",
    "        a = a + 1\n",
    "    if i not in vent_nums:\n",
    "        vent_testing[:, v] = vent_full[:,i]\n",
    "        v = v + 1\n",
    "\n",
    "##Plot Training & Testing data as a function of time\n",
    "fs=500\n",
    "a_time= np.arange(np.size(atrial_training, 0))\n",
    "a_time= a_time/fs\n",
    "v_time= np.arange(np.size(vent_training, 0))\n",
    "v_time= v_time/fs\n",
    "\n",
    "plt.figure()\n",
    "plt.title (\"Normalized Atrial Training Signals\")\n",
    "plt.xlabel (\"Time (s)\")\n",
    "plt.ylabel (\"Normalized Potential\")\n",
    "a =plt.plot(a_time, atrial_training)\n",
    "\n",
    "plt.figure()\n",
    "plt.title (\"Normalized Ventricular Training Signals\")\n",
    "plt.xlabel (\"Time (s)\")\n",
    "plt.ylabel (\"Normalized Potential\")\n",
    "b = plt.plot (v_time, vent_training)\n",
    "\n",
    "\n",
    "###Identify true classifications of training and testing examples\n",
    "#Training, assigning -1 for atrial and 1 for ventricular\n",
    "classifier= np.zeros(200)\n",
    "for i in range (100):\n",
    "    classifier[i]=-1\n",
    "for j in range (100, 200):\n",
    "    classifier[j]=1\n",
    "\n",
    "#Testing, apply the same logic\n",
    "truth = np.zeros(1800)\n",
    "for i in range(900):\n",
    "    truth[i] = -1\n",
    "for j in range(900,1800):\n",
    "    truth[j] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hand-crafted Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A function to identify the value in an array closest to a given value\n",
    "def find_nearest(array, value):\n",
    "    idx = ((np.abs(array - value)).argmin())\n",
    "    return idx\n",
    "\n",
    "#A function to identify the value of the APD at x*100% for a given action potential (signals)\n",
    "def apd (signals, x):\n",
    "    apd= np.zeros(np.size(signals,1))\n",
    "    for i in range (np.size(signals,1)):\n",
    "        max=np.argmax(signals[:,i])\n",
    "        x_index= find_nearest(signals[:,i] [max:], x)\n",
    "        apd[i]=x_index/500\n",
    "    return apd\n",
    "    \n",
    "#A function to compute the average of the given action potential (signals)\n",
    "def aap (signals):\n",
    "    aap= np.zeros(np.size(signals,1))\n",
    "    for i in range (np.size(signals,1)):\n",
    "        aap[i]= np.mean(signals[:,i])\n",
    "    return aap\n",
    "\n",
    "#calculating APD and AAP of the atrial training data and storing in separate vectors\n",
    "APD_atrial=apd(atrial_training, .5)\n",
    "APD2_atrial = apd(atrial_training, .2)\n",
    "APD3_atrial = apd(atrial_training, .8)\n",
    "AAP_atrial=aap(atrial_training)\n",
    "\n",
    "#calculating APD and AAP of the ventricular training data and storing in separate vectors\n",
    "APD_vent=apd(vent_training, .5)\n",
    "APD2_vent = apd(vent_training, .2)\n",
    "APD3_vent = apd(vent_training, .8)\n",
    "AAP_vent=aap(vent_training)\n",
    "\n",
    "\n",
    "#creating a matrix by concatenating the APD and AAP features of the atrial training data\n",
    "atrial_featTrain=np.zeros((np.size(APD_atrial), 4))\n",
    "atrial_featTrain[:,0]= APD_atrial\n",
    "atrial_featTrain[:,1]= AAP_atrial\n",
    "atrial_featTrain[:,2] = APD2_atrial\n",
    "atrial_featTrain[:,3] = APD3_atrial\n",
    "\n",
    "#creating a matrix by concatenating the APD and AAP features of the ventricular training data\n",
    "vent_featTrain=np.zeros((np.size(APD_vent), 4))\n",
    "vent_featTrain[:,0]= APD_vent\n",
    "vent_featTrain[:,1]= AAP_vent\n",
    "vent_featTrain[:, 2] = APD2_vent\n",
    "vent_featTrain[:, 3] = APD3_vent\n",
    "\n",
    "#calculating APD and AAP of the atrial testing data and storing in separate matrices\n",
    "APD_atrialtest=apd(atrial_testing, .5)\n",
    "AAP_atrialtest=aap(atrial_testing)\n",
    "APD2_atrialtest = apd(atrial_testing, .2)\n",
    "APD3_atrialtest = apd(atrial_testing, .8)\n",
    "\n",
    "#calculating APD and AAP of the ventricular testing data and storing in separate matrices\n",
    "APD_venttest=apd(vent_testing, .5)\n",
    "AAP_venttest=aap(vent_testing)\n",
    "APD2_venttest = apd(vent_testing, .2)\n",
    "APD3_venttest = apd(vent_testing, .8)\n",
    "\n",
    "#creating a matrix by concatenating the APD and AAP features of the atrial testing data\n",
    "atrial_featTest=np.zeros((np.size(APD_atrialtest), 4))\n",
    "atrial_featTest[:,0]= APD_atrialtest\n",
    "atrial_featTest[:,1]= AAP_atrialtest\n",
    "atrial_featTest[:, 2] = APD2_atrialtest\n",
    "atrial_featTest[:, 3] = APD3_atrialtest\n",
    "\n",
    "#creating a matrix by concatenating the APD and AAP features of the ventricular testing data\n",
    "vent_featTest=np.zeros((np.size(APD_venttest), 4))\n",
    "vent_featTest[:,0]= APD_venttest\n",
    "vent_featTest[:,1]= AAP_venttest\n",
    "vent_featTest[:, 2] = APD2_venttest\n",
    "vent_featTest[:, 3] = APD3_venttest\n",
    "\n",
    "print(atrial_featTrain.shape)\n",
    "\n",
    "#Plotting each action potential by its APD50 value (x axis) and AAP value (y axis)\n",
    "plt.figure()\n",
    "plt.plot(atrial_featTrain[:,3], atrial_featTrain[:,2], 'ro', label='Atrial Data')\n",
    "plt.plot(vent_featTrain[:,3], vent_featTrain[:,2], 'bo', label='Ventricular Data')\n",
    "plt.title (\"APD50 and AAP Features of Atrial and Ventricular Potentials\")\n",
    "plt.xlabel(\"APD50\")\n",
    "plt.ylabel(\"AAP\")\n",
    "plt.legend ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA & Fourier Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "#Compute PCA coefficients\n",
    "def PCA_features(signals):\n",
    "    pca = PCA(n_components=10)\n",
    "    pca.fit(np.transpose(signals))\n",
    "    newComp = pca.transform(np.transpose(signals))\n",
    "    return newComp\n",
    "\n",
    "#Compute fourier coefficients\n",
    "def Fourier(signals):\n",
    "    fourierTransform = np.fft.fft(signals, axis = 0)\n",
    "    f_coeff= fourierTransform[: 10]\n",
    "    return np.abs(f_coeff)\n",
    "\n",
    "#Combine training examples\n",
    "full_training= np.concatenate((atrial_training, vent_training), 1)\n",
    "full_apdTraining = np.vstack((atrial_featTrain, vent_featTrain))\n",
    "\n",
    "\n",
    "#Combine testing examples\n",
    "full_testing = np.concatenate((atrial_testing, vent_testing), 1)\n",
    "full_apdTesting = np.vstack((atrial_featTest, vent_featTest))\n",
    "\n",
    "#Compute pca coefficients of training examples\n",
    "PCA_training= PCA_features(full_training)\n",
    "#Compute fourier coefficients of training examples\n",
    "Fourier_training=Fourier(full_training)\n",
    "Fourier_test = Fourier(full_testing)\n",
    "print(full_apdTraining.shape)\n",
    "print(Fourier_training.shape)\n",
    "\n",
    "fullTrainingFeats = np.hstack((full_apdTraining, np.transpose(Fourier_training)))\n",
    "fullTestingFeats = np.hstack((full_apdTesting, np.transpose(Fourier_test)))\n",
    "\n",
    "\n",
    "#Plot coefficients of pca and fourier over training examples\n",
    "#Examples 100-199 are ventricular\n",
    "#Examples 0-99 are atrial\n",
    "plt.figure()\n",
    "plt.plot (PCA_training)\n",
    "plt.title(\"PCA coefficients of training examples\")\n",
    "plt.xlabel(\"Training example number\")\n",
    "plt.ylabel(\"Coefficient value\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot (np.transpose(Fourier_training))\n",
    "plt.title(\"Fourier coefficients of training examples\")\n",
    "plt.xlabel(\"Training example number\")\n",
    "plt.ylabel(\"Coefficient value\")\n",
    "\n",
    "\n",
    "#Plot testing signals\n",
    "plt.figure(figsize = (12, 12))\n",
    "plt.title (\"All Signals\", fontsize = 30)\n",
    "plt.xlabel (\"Time (s)\", fontsize = 30)\n",
    "plt.ylabel (\"Normalized Potential\", fontsize = 30)\n",
    "a = plt.plot(a_time, full_testing)\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis = 'both', which = 'major', labelsize = 24)\n",
    "ax.tick_params(axis = 'both', which = 'minor', labelsize = 24)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computes classifications of new set of examples using nearest neighbor method with training examples using fourier coeff.\n",
    "def NNfourier (training, training_label, new):\n",
    "    new_class= np.zeros(np.size(new,1))\n",
    "    fourierNew=np.fft.fft(new ,axis=0)\n",
    "    fourierTrain= np.fft.fft(training, axis=0)\n",
    "    fourierNew = np.abs(fourierNew[:10, :])\n",
    "    fourierTrain = np.abs(fourierTrain[:10, :])\n",
    "    \n",
    "    for i in range (np.size(new, 1)):\n",
    "        coeff=np.abs(fourierNew[:, i])\n",
    "        distances=np.zeros(np.size(training,1))\n",
    "        for j in range (np.size(training,1)):\n",
    "            distances[j]=np.linalg.norm(coeff-fourierTrain[:, j])\n",
    "        min_ind=np.argmin(distances)\n",
    "        new_class[i]= training_label [min_ind]\n",
    "    return new_class\n",
    "\n",
    "\n",
    "#Compute new classifications using function defined above\n",
    "NNresults= NNfourier(full_training, classifier, full_testing)\n",
    "\n",
    "#Output number of wrong classifications\n",
    "print(\"Number of wrong classifications:\", sum(NNresults + truth == 0))\n",
    "\n",
    "#plotting classifications\n",
    "#0-899 = atrial\n",
    "#900-1799 = ventricular\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(NNresults, 'bo')\n",
    "plt.xlabel(\"Testing example number\")\n",
    "plt.ylabel(\"Classification: positive = vent, negative = atrial\")\n",
    "plt.title(\"Classification of testing set using NN, fourier features. Truth in red.\")\n",
    "plt.plot(truth*.9, 'ro')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear classifier, manually\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "#### FUNCTIONS ####\n",
    "###################\n",
    "\n",
    "#Calculate loss of individual action potential (helper function)\n",
    "def loss (w, b, data, labels, i):\n",
    "    f= np.matmul(np.transpose(data[i, :]), w)+ b\n",
    "    y=labels[i]\n",
    "    loss= np.exp(-f*y)\n",
    "    return loss\n",
    "\n",
    "#Calculate the cost function at a certain w, b\n",
    "def reg_risk (w, b, penalty, data, labels):\n",
    "    N= np.size(labels)\n",
    "    sum=0\n",
    "    for i in range (N):\n",
    "        sum= sum+ loss(w,b,data,labels,i)\n",
    "    sum= sum/N   \n",
    "    sum+= .5*penalty*(np.linalg.norm(w)**2)\n",
    "    return sum\n",
    "\n",
    "#Calculate gradient with respect to w and b\n",
    "def gradient (w,b, penalty, data, labels):\n",
    "    wsum = 0\n",
    "    for i in range(0, np.size(data, 0)):\n",
    "        wsum += -labels[i] * loss(w, b, data, labels, i) * data[i, :]\n",
    "    wsum = wsum*(1/np.size(data, 0))\n",
    "    wsum+= w*penalty\n",
    "    bsum = 0\n",
    "    for i in range(0, np.size(data, 0)):\n",
    "        bsum += -labels[i] * loss(w, b, data, labels, i)\n",
    "    bsum = bsum*(1/np.size(data,0))\n",
    "    \n",
    "    return wsum, bsum\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "#This function does gradient descent on w and b to minimize the cost (exponential w/ regularization)\n",
    "def opti_coeff (training_data, training_labels, num_iterations, a0set = .25, pen = 1):\n",
    "    #Set penalty\n",
    "    penalty= pen\n",
    "    #Set w to start at 0 vector initially\n",
    "    w=np.zeros(np.size (training_data,1))\n",
    "    for i in range(np.size(w,0)):\n",
    "        w[i] = 0.0\n",
    "    #Set b to start at 0\n",
    "    b=0.0\n",
    "    #set initial step\n",
    "    a0 = a0set\n",
    "    a = np.zeros(num_iterations)\n",
    "    for i in range(num_iterations):\n",
    "        a[i] = a0/np.sqrt(i+1)\n",
    "    for i in range (num_iterations):\n",
    "        #Calculate gradient with respect to w and b\n",
    "        gradw, gradb = gradient(w, b, penalty, training_data, training_labels)\n",
    "        #move in opposite direction of gradient to find minimum, move by given step in that direction\n",
    "        w = w - a[i] * gradw\n",
    "        b = b - a[i] * gradb\n",
    "\n",
    "    return w, b\n",
    "\n",
    "#This function was used to normalize each fourier feature from 0 to 1 \n",
    "#and was necessary because we were encountering overflow issues due to the exponent\n",
    "def normalizeFeatures(data):\n",
    "    new = np.zeros(np.size(data, 1))\n",
    "    for i in range(np.size(data, 0)):\n",
    "        min = np.min(data[i, :])\n",
    "        max = np.max(data[i, :])\n",
    "        new = (data[i, :] - min)/ (max - min) \n",
    "        data[i, :] = new\n",
    "    return data\n",
    "\n",
    "\n",
    "####################\n",
    "### INITIALIZING ###\n",
    "####################\n",
    "\n",
    "#compute fourier features for training and testing set.\n",
    "fourierNew=np.fft.fft(full_testing ,axis=0)\n",
    "fourierTrain= np.fft.fft(full_training, axis=0)\n",
    "fourierNew = np.abs(fourierNew[:10, :])\n",
    "fourierTrain = np.abs(fourierTrain[:10, :])\n",
    "fourierNew = normalizeFeatures(fourierNew) #done to avoid overflow issues\n",
    "fourierTrain = normalizeFeatures(fourierTrain)\n",
    "fourierNew = np.transpose(fourierNew) ## 1800 testing examples by 10 features per example\n",
    "fourierTrain = np.transpose(fourierTrain) ## 200 examples by 10 features per example\n",
    "\n",
    "\n",
    "\n",
    "########################\n",
    "### Gradient Descent ###\n",
    "########################\n",
    "\n",
    "#Set number of trials\n",
    "numtrials = 150\n",
    "risks = np.zeros(numtrials)\n",
    "\n",
    "#Run gradient descent for each 1, 2, ... numtrials\n",
    "for trial in np.arange(numtrials):\n",
    "    #run gradient descent\n",
    "    w, b = opti_coeff(fourierTrain, classifier, trial + 1, .1, 1)\n",
    "    #calculate corresponding cost with w, b after \"trial\" iterations of gradient descent\n",
    "    risks[trial] = reg_risk(w, b, 1, fourierTrain, classifier)\n",
    "\n",
    "    \n",
    "################\n",
    "### Plotting ###\n",
    "################\n",
    "\n",
    "#plotting exponential lost in range -2, 2\n",
    "plt.figure()\n",
    "myrange = np.linspace(-2, 2, 1000)\n",
    "vals = np.exp(-1*myrange)\n",
    "plt.plot(myrange, vals)\n",
    "plt.title(\"Exponential loss function in range -2, 2\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"exp(-x)\")\n",
    "\n",
    "#plotting the cost function vs number of iterations\n",
    "plt.figure()\n",
    "plt.plot(np.arange(1, numtrials+1), risks)\n",
    "plt.title(\"Cost Function vs Number of grad. descent iterations (a = .1, Fourier)\")\n",
    "plt.xlabel(\"Number of Iterations\")\n",
    "plt.ylabel(\"Cost Function\")\n",
    "\n",
    "#plotting f(x) on the testing set\n",
    "testpredictions = np.matmul(fourierNew, w) + b\n",
    "plt.figure()\n",
    "plt.plot(testpredictions)\n",
    "plt.title(\"f(x) = wTx + b on test data (Fourier features, a = .1, pen = 1)\")\n",
    "plt.xlabel(\"Action potential number\")\n",
    "plt.ylabel(\"f(x), pos = vent, neg = atrial\")\n",
    "\n",
    "testclassifications = 2*((testpredictions >0) - .5)\n",
    "#plotting classifications vs truth\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(testclassifications, 'bo')\n",
    "plt.xlabel(\"Testing example number\")\n",
    "plt.ylabel(\"Classification: positive = vent, negative = atrial\")\n",
    "plt.title(\"Classification of testing set using linear classifier, fourier features. Truth in red.\")\n",
    "plt.plot(truth*.9, 'ro')\n",
    "\n",
    "##################\n",
    "### Questions ####\n",
    "##################\n",
    "print(\"Expression for the gradient of the cost function with respect to w = (1/N * the sum from 1 to N of (y*x*expoential loss)) + lambda*w\")\n",
    "print(\"Expression for the gradient of the cost function with respect to w = (1/N * the sum from 1 to N of (y*expoential loss))\")\n",
    "print(\"Number of wrong classifications:\", sum(testclassifications + truth == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on test set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Making training and testing data for each feature\n",
    "\n",
    "APD_atrialtrain=apd(atrial_training, .1)\n",
    "AAP_atrialtrain=aap(atrial_training)\n",
    "\n",
    "APD_venttrain=apd(vent_training, .1)\n",
    "AAP_venttrain=aap(vent_training)\n",
    "\n",
    "APD_atrialtest = apd(atrial_testing, .1)\n",
    "AAP_atrialtest=aap(atrial_testing)\n",
    "\n",
    "APD_venttest=apd(vent_testing, .1)\n",
    "AAP_venttest=aap(vent_testing)\n",
    "\n",
    "atrial_featTrain=np.zeros((np.size(APD_atrialtrain), 2))\n",
    "atrial_featTrain[:,0]= APD_atrialtrain\n",
    "atrial_featTrain[:,1]= AAP_atrialtrain\n",
    "\n",
    "vent_featTrain=np.zeros((np.size(APD_venttrain), 2))\n",
    "vent_featTrain[:,0]= APD_venttrain\n",
    "vent_featTrain[:,1]= AAP_venttrain\n",
    "\n",
    "atrial_featTest=np.zeros((np.size(APD_atrialtest), 2))\n",
    "atrial_featTest[:,0]= APD_atrialtest\n",
    "atrial_featTest[:,1]= AAP_atrialtest\n",
    "\n",
    "vent_featTest=np.zeros((np.size(APD_venttest), 2))\n",
    "vent_featTest[:,0]= APD_venttest\n",
    "vent_featTest[:,1]= AAP_venttest\n",
    "\n",
    "#handcrafted feature made by concantenating atrial and ventricular training + testing data\n",
    "featTrain = np.concatenate((atrial_featTrain, vent_featTrain), 0)\n",
    "featTest = np.concatenate((atrial_featTest, vent_featTest), 0)\n",
    "\n",
    "\n",
    "#PCA\n",
    "pca = PCA(n_components=10)\n",
    "pca.fit(np.transpose(full_training))\n",
    "traincomp = pca.transform(np.transpose(full_training))\n",
    "testcomp = pca.transform(np.transpose(full_testing))\n",
    "\n",
    "#Fourier\n",
    "trainfourier = fourierTrain\n",
    "testfourier = fourierNew\n",
    "\n",
    "##########################\n",
    "### 1NN Classification ###\n",
    "##########################\n",
    "\n",
    "#Function that classifies testing data by using the nearest neighbor in the training data set\n",
    "def NNgeneral(train, trainlabel, test):\n",
    "    testLabel= np.zeros(np.size(test,0))\n",
    "    for i in range (np.size(test, 0)):\n",
    "        distances=np.zeros(np.size(train,0))\n",
    "        for j in range (np.size(train,0)):\n",
    "            distances[j]=np.linalg.norm(test[i, :] - train[j, :])\n",
    "        min_ind=np.argmin(distances)\n",
    "        if(min_ind > 200):\n",
    "            min_ind = 0\n",
    "        testLabel[i]= trainlabel [min_ind]\n",
    "    return testLabel\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#compute nearest neighbor classifications for testing sets for each feature\n",
    "featResults = NNgeneral(featTrain, classifier, featTest)\n",
    "pcaResults = NNgeneral(traincomp, classifier, testcomp)\n",
    "fourierResults = NNgeneral(trainfourier, classifier, testfourier)\n",
    "\n",
    "#Outputting classification results\n",
    "print(\"Nearest Neighbor handcrafted Number of wrong classifications:\", sum(featResults + truth == 0))\n",
    "print(\"Testing classification accuracy for NN handcrafted feature = \", sum(featResults + truth != 0)/np.size(truth))\n",
    "print(\"Nearest Neighbor PCA Number of wrong classifications:\", sum(pcaResults + truth == 0))\n",
    "print(\"Testing classification accuracy for NN PCA = \", sum(pcaResults + truth != 0)/np.size(truth))\n",
    "print(\"Nearest Neighbor Fourier Number of wrong classifications:\", sum(fourierResults + truth == 0))\n",
    "print(\"Testing classification accuracy for NN Fourier = \", sum(fourierResults + truth != 0)/np.size(truth))\n",
    "print()\n",
    "\n",
    "#Plotting classification results\n",
    "#0-899 atrial\n",
    "#900-1799 ventricular\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(featResults, 'bo')\n",
    "plt.xlabel(\"Testing example number\")\n",
    "plt.ylabel(\"Classification: positive = vent, negative = atrial\")\n",
    "plt.title(\"Classification of testing set using nearest neighbor, handcraft features. Truth in red.\")\n",
    "plt.plot(truth*.9, 'ro')\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(pcaResults, 'bo')\n",
    "plt.xlabel(\"Testing example number\")\n",
    "plt.ylabel(\"Classification: positive = vent, negative = atrial\")\n",
    "plt.title(\"Classification of testing set using nearest neighbor, pca features. Truth in red.\")\n",
    "plt.plot(truth*.9, 'ro')\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(fourierResults, 'bo')\n",
    "plt.xlabel(\"Testing example number\")\n",
    "plt.ylabel(\"Classification: positive = vent, negative = atrial\")\n",
    "plt.title(\"Classification of testing set using nearest neighbor, fourier features. Truth in red.\")\n",
    "plt.plot(truth*.9, 'ro')\n",
    "\n",
    "#3b\n",
    "#########################\n",
    "### Linear Classifier ###\n",
    "#########################\n",
    "\n",
    "#calculating optimal w and b (numtrials and initial step tuned below)\n",
    "wfeat, bfeat = opti_coeff(featTrain, classifier, 200, 1, pen = .1)\n",
    "wpca, bpca = opti_coeff(traincomp, classifier, 100, .1, pen = 1)\n",
    "wfour, bfour = opti_coeff(trainfourier, classifier, 100, .25, pen = 1)\n",
    "\n",
    "#Run gradient descent for each 1, 2, ... numtrials handcrafted features\n",
    "numtrialfeat = 125\n",
    "risksfeat = np.zeros(numtrialfeat)\n",
    "trainingAccfeat = np.zeros(numtrialfeat)\n",
    "testingAccfeat = np.zeros(numtrialfeat)\n",
    "for trial in np.arange(numtrialfeat):\n",
    "    #run gradient descent\n",
    "    w, b = opti_coeff(featTrain, classifier, trial, 1, .1)\n",
    "    #calculate corresponding cost with w, b after \"trial\" iterations of gradient descent\n",
    "    risksfeat[trial] = reg_risk(w, b, .1, featTrain, classifier)\n",
    "    #calc train/test accuracies\n",
    "    trainpred = np.matmul(featTrain, w) + b\n",
    "    trainclass = 2*((trainpred >0) -.5)\n",
    "    testpred = np.matmul(featTest, w) + b\n",
    "    testclass = 2*((testpred > 0) -.5)\n",
    "    trainingAccfeat[trial] = sum(trainclass + classifier != 0)/np.size(classifier)\n",
    "    testingAccfeat[trial] = sum(testclass + truth != 0)/np.size(truth)\n",
    "\n",
    "#Run gradient descent for each 1, 2, ... numtrials pca\n",
    "numtrialpca = 25\n",
    "riskspca = np.zeros(numtrialpca)\n",
    "trainingAccpca = np.zeros(numtrialpca)\n",
    "testingAccpca = np.zeros(numtrialpca)\n",
    "\n",
    "\n",
    "for trial in np.arange(numtrialpca):\n",
    "    #run gradient descent\n",
    "    w, b = opti_coeff(traincomp, classifier, trial, .1, 1)\n",
    "    #calculate corresponding cost with w, b after \"trial\" iterations of gradient descent\n",
    "    riskspca[trial] = reg_risk(w, b, 1, traincomp, classifier)\n",
    "    #calc train/test accuracies\n",
    "    trainpred = np.matmul(traincomp, w) + b\n",
    "    trainclass = 2*((trainpred >0) -.5)\n",
    "    testpred = np.matmul(testcomp, w) + b\n",
    "    testclass = 2*((testpred > 0) -.5)\n",
    "    trainingAccpca[trial] = sum(trainclass + classifier != 0)/np.size(classifier)\n",
    "    testingAccpca[trial] = sum(testclass + truth != 0)/np.size(truth)\n",
    "    \n",
    "\n",
    "    \n",
    "#Run gradient descent for each 1, 2, ... numtrials fourier\n",
    "numtrialfour = 100\n",
    "risksfour = np.zeros(numtrialfour)\n",
    "trainingAccfour = np.zeros(numtrialfour)\n",
    "testingAccfour = np.zeros(numtrialfour)\n",
    "for trial in np.arange(numtrialfour):\n",
    "    #run gradient descent\n",
    "    w, b = opti_coeff(trainfourier, classifier, trial, .25, 1)\n",
    "    #calculate corresponding cost with w, b after \"trial\" iterations of gradient descent\n",
    "    risksfour[trial] = reg_risk(w, b, 1, trainfourier, classifier)\n",
    "    #calc train/test accuracies\n",
    "    trainpred = np.matmul(trainfourier, w) + b\n",
    "    trainclass = 2*((trainpred >0) -.5)\n",
    "    testpred = np.matmul(testfourier, w) + b\n",
    "    testclass = 2*((testpred > 0) -.5)\n",
    "    trainingAccfour[trial] = sum(trainclass + classifier != 0)/np.size(classifier)\n",
    "    testingAccfour[trial] = sum(testclass + truth != 0)/np.size(truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "featTrain = fullTrainingFeats\n",
    "featTest = fullTestingFeats\n",
    "\n",
    "pca = PCA(n_components=14)\n",
    "pca = pca.fit(normalize(featTrain))\n",
    "plt.xlabel(\"Component Number\")\n",
    "plt.xlabel(\"\")\n",
    "\n",
    "plt.figure(figsize = (12,12))\n",
    "expVar = pca.explained_variance_ratio_\n",
    "expVarCum = np.cumsum(expVar)\n",
    "\n",
    "print(expVar)\n",
    "plt.plot(np.arange(1, 15), expVar)\n",
    "plt.plot(np.arange(1, 15), expVarCum)\n",
    "plt.xlabel(\"Principal components\", fontsize = 30)\n",
    "plt.ylabel(\"Explained Variance Ratio\", fontsize = 30)\n",
    "#plt.legend(\"Explained Variance, Cumulative Explained Variance\")\n",
    "plt.title(\"Explained Variance (Orange = Cumulative)\", fontsize = 30)         \n",
    "newFeatTrain=pca.transform(normalize(featTrain))\n",
    "newFeatTest=pca.transform(normalize(featTest))\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis = 'both', which = 'major', labelsize = 24)\n",
    "ax.tick_params(axis = 'both', which = 'minor', labelsize = 24)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "pca = PCA(n_components = 1)\n",
    "pca = pca.fit(normalize(featTrain))\n",
    "featTrain=pca.transform(normalize(featTrain))\n",
    "featTest=pca.transform(normalize(featTest))\n",
    "\n",
    "featTrain = fullTrainingFeats\n",
    "featTest = fullTestingFeats\n",
    "\n",
    "features = np.array([\"APD50\", \"AAP\", \"APD80\", \"APD20\", \"F1\", \"F2\", \"F3\", \"F4\", \"F5\", \"F6\", \"F7\", \"F8\", \"F9\", \"F10\"])\n",
    "featTrain = normalize(featTrain, axis = 0)\n",
    "featTest = normalize(featTest, axis = 0)\n",
    "toPlot = featTrain[80:120, :]\n",
    "import seaborn as sns; sns.set(rc={'figure.figsize':(10,10)})\n",
    "sns.set(font_scale=1.4)\n",
    "plt.tight_layout()\n",
    "fig = plt.figure()\n",
    "ax = sns.heatmap(toPlot, annot_kws={\"size\": 20}, xticklabels = features) #vmax = .1\n",
    "ax.set_xlabel(\"Features\", fontsize = 20)\n",
    "ax.set_ylabel(\"Ventricular                               Atrial\", fontsize = 20)\n",
    "ax.set_title(\"Normalized Feature Value\", fontsize = 20)\n",
    "\n",
    "fig.savefig(\"heat.png\", bbox_inches = \"tight\")\n",
    "\n",
    "featTrain = np.vstack((featTrain, featTrain, featTrain))\n",
    "featTest = np.vstack((featTest, featTest, featTest))\n",
    "#trainclass = np.hstack((trainclass, trainclass, trainclass))\n",
    "#testclass = np.hstack((testclass, testclass, testclass))\n",
    "featTrain = np.vstack((featTrain, featTrain, featTrain))\n",
    "featTest = np.vstack((featTest, featTest, featTest))\n",
    "featTrain = np.vstack((featTrain, featTrain, featTrain))\n",
    "featTest = np.vstack((featTest, featTest, featTest))\n",
    "featTrain = np.vstack((featTrain, featTrain, featTrain))\n",
    "featTest = np.vstack((featTest, featTest, featTest))\n",
    "#trainclass = np.hstack((trainclass, trainclass, trainclass))\n",
    "#testclass = np.hstack((testclass, testclass, testclass))\n",
    "\n",
    "glf_start = time.time()\n",
    "glf = LogisticRegression().fit(featTrain,trainclass)\n",
    "glf_end = time.time()\n",
    "glf_time = glf_end-glf_start\n",
    "\n",
    "\n",
    "print('Logistic Regression: ', glf.score(featTest,testclass))\n",
    "print('It took ',glf_time)\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "gnbb_start = time.time()\n",
    "gnbb = GaussianNB().fit(featTrain,trainclass)\n",
    "gnbb_end = time.time()\n",
    "gnbb_time = gnbb_end - gnbb_start\n",
    "\n",
    "\n",
    "print('\\n\\nGaussian Naive Bayes: ', gnbb.score(featTest,testclass))\n",
    "print('It took ', gnbb_time)\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "sv_start = time.time()\n",
    "sv = SVC().fit(featTrain,trainclass)\n",
    "sv_end = time.time()\n",
    "sv_time = sv_end - sv_start\n",
    "\n",
    "print('\\n\\nSVC: ', sv.score(featTest,testclass))\n",
    "print('It took ',sv_time)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_start = time.time()\n",
    "knnn = KNeighborsClassifier().fit(featTrain,trainclass)\n",
    "knn_end = time.time()\n",
    "knn_time = knn_end - knn_start\n",
    "\n",
    "print('\\n\\nKNN: ', knnn.score(featTest,testclass))\n",
    "print('It took ',knn_time)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "rf_start = time.time()\n",
    "rf = RandomForestClassifier().fit(featTrain,trainclass)\n",
    "rf_end = time.time()\n",
    "rf_time = rf_end - rf_start\n",
    "\n",
    "print('\\n\\nRandom Forest: ', rf.score(featTest,testclass))\n",
    "print('It took ', rf_time)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "dt_start = time.time()\n",
    "dt = DecisionTreeClassifier().fit(featTrain,trainclass)\n",
    "dt_end = time.time()\n",
    "dt_time = dt_end - dt_start\n",
    "\n",
    "\n",
    "print('\\n\\nDecision Tree: ', dt.score(featTest,testclass))\n",
    "\n",
    "print('It took: ', dt_time)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
